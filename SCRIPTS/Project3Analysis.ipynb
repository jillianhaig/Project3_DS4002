{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jillianhaig/Project3_DS4002/blob/main/SCRIPTS/Project3Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJYvZN8CUpnr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# This file connects to our shared google folder in Google Drive and pulls the unzips the data in through Colab, then stores the images locally on colab\n",
        "# We can then simply reference the paths for the image analysis that we will do later instead of the full image\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive to access the dataset\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the zip file on Google Drive\n",
        "zip_file_path = '/content/drive/My Drive/DS4002 Projects/Project 3/vehicleimages.zip'\n",
        "\n",
        "# Directory where you want to extract the files\n",
        "extract_to_path = '/content/vehicleimages'\n",
        "\n",
        "# Unzip the dataset\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "\n",
        "print(f\"Dataset unzipped to: {extract_to_path}\")\n",
        "\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "vehicle_types = os.listdir(extract_to_path)\n",
        "\n",
        "# For each subdirectory, get image paths\n",
        "for vehicle_type in vehicle_types:\n",
        "    vehicle_folder = os.path.join(extract_to_path, vehicle_type)\n",
        "\n",
        "    if os.path.isdir(vehicle_folder):\n",
        "        for img_file in os.listdir(vehicle_folder):\n",
        "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "                image_path = os.path.join(vehicle_folder, img_file)\n",
        "                image_paths.append(image_path)\n",
        "                labels.append(vehicle_type)\n",
        "\n",
        "df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
        "\n",
        "csv_file_path = '/content/vehicle_images_dataset.csv'\n",
        "# Saves dataset in the /content directory on Google Colab so we can easily access it,\n",
        "# then it will pull from the actual images which are also now saved under content\n",
        "\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "# Optional download of data\n",
        "# files.download(csv_file_path)\n",
        "\n",
        "print(df.head())"
      ]
    }
  ]
}